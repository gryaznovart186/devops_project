# Итоговый проект по курсу «DevOps практики и инструменты»
Authors: rustsh & gryaznovart186

## Описание проекта
будет добавлено позже

## Запуск проекта
### Требуемые программы и инструменты
- Git
- Terraform
- Ansible
- Google Cloud SDK

### Предварительные шаги
1. Установить все требуемые программы.
2. Создать проект в Google Cloud Platform.
3. В метаданные проекта добавить открытые SSH-ключи пользователей, которые будут работать с инфраструктурой.
4. Создать Application Default Credentials для предоставления доступа к облачной инфраструктуре инструментам:
    ```bash
    $ gcloud auth application-default login
    ```

### Создание инфраструктуры:
Сначала нужно создать облачное хранилище для state-файлов — отдельно от основной инфраструктуры, чтобы не было конфликтов при её удалении и пересоздании:
1. Перейти в папку **terraform/storage/**.
2. Переименовать файл **terraform.tfvars.example** в **terraform.tfvars**, внутри него указать название проекта.
3. Выполнить команду `terraform init`, после чего — `terraform apply`. Дождаться создания облачного хранилища.

Теперь можно создать саму инфрастуктуру. Для этого нужно перейти в папку **terraform/**, повторить пункты 2–3 и дождаться создания инфраструктуры (выполнение — около 1,5 минуты).

#### Результат
В GCP создана сеть **devops-project-network**, в ней находятся четыре виртуальные машины со статическими IP-адресами и правила файервола для доступа к ним. SSH-ключи уже добавлены из метаданных проекта.
Отдельно создано хранилище с названием **devops-project-storage-bucket**, в котором содержатся state-файлы инфраструктуры.

### Подготовка инфраструктуры:
1. Перейти в папку **ansible/**.
2. Переименовать файл **ansible.cfg.example** в **ansible.cfg**, а **inventory.example** в **inventory**. В файле **ansible.cfg** указать логин пользователя, от которого будут выполняться плейбуки, и расположение закрытого SSH-ключа. В файле **inventory** в соответствующих группах нужно перечислить актуальные IP-адреса созданных виртуальных машин.
3. Задать настройки для интеграции Alertmanager и Slack:
    - создать Incoming WebHook в пространстве Slack;
    - указать Webhook URL и название канала для оповещений в файле **roles\alertmanager\files\alertmanager.yml**.
4. Выполнить плейбук **playbooks/start.yml** (выполнение — около 10,5 минут):
    ```bash
    $ ansible-playbook playbooks/start.yml
    ```
5. Сделать предварительные настройки Gitlab'а в графическом интерфейсе:
    - открыть страницу **http://<ci-IP>**;
    - задать пароль для пользователя Administrator, после чего зайти с логином `root` и этим паролем;
    - создать группу для проектов. Сразу же можно создать проекты и переменные окружения — более подробно они будут описаны далее;
    - в настройках группы в разделе **CI/CD** раскрыть блок **Runners** и скопировать регистрационный токен.
6. Установить и зарегистрировать раннер Gitlab'а. Для этого необходимо указать сохранённый на предыдущем шаге токен как значение переменной `registration_token` в файле **playbooks/gitlab-runner.yml** и выполнить сам плейбук:
    ```bash
    $ ansible-playbook playbooks/gitlab-runner.yml
    ```
7. Настроить Grafana в графическом интерфейсе:
    - открыть страницу **http://<monitor-IP>:3000**;
    - авторизоваться в системе со стандартными логином и паролем (`admin` для обоих значений), изменить пароль;
    - указать Prometheus в качестве источника данных;
    - загрузить дашборды из папки **grafana-dashboards/**.

#### Результат
1. На всех виртуальных машинах обновлена операционная система и все предустановленные пакеты, отключены firewalld и SELinux, установлен и запущен Docker.
2. На машине **ci** установлены и запущены в контейнерах Gitlab и раннер, создана группа для проектов, раннер зарегистрирован и доступен для этой группы.
3. На машине **monitor** установлены и настроены Prometheus, Grafana и Alertmanager. Для них поднята единая сеть (docker network). Настроена интеграция Alertmanager и Slack.
4. На машине **prod** установлены экспортеры для системы мониторинга: cAdvisor, Node Exporter и RabbitMQ Exporter.
5. На машинах **ci**, **stage** и **prod** создан пользователь для деплоя приложения. На машине **ci** создана пара SSH-ключей для этого пользователя, открытый ключ скопирован в файл **authorized_keys** на машинах **stage** и **prod**.
6. На машинах **stage** и **prod** запущены MongoDB и RabbitMQ в контейнерах, в RabbitMQ создана очередь **urls**. Для них, а также для компонентов приложения и экспортеров, поднята единая сеть (docker network).

### Деплой приложения
1. В созданной ранее группе проектов Gitlab создать два новых проекта: один для приложения, другой для интерфейса.
2. В настройках группы в разделе **CI/CD** раскрыть блок **Variables** и создать переменные окружения:
    - `DOCKER_REGISTRY_USER` — логин пользователя Docker Hub, в чей репозиторий будут загружаться создаваемые образы приложения;
    - `DOCKER_REGISTRY_PASSWORD` — пароль пользователя Docker Hub;
    - `RMQ_USERNAME` — логин пользователя RabbitMQ, который задаётся в файле **ansible\roles\rabbitmq\tasks\main.yml**. В нашем случае — `admin`;
    - `RMQ_PASSWORD` — пароль пользователя RabbitMQ, который задаётся в файле **ansible\roles\rabbitmq\tasks\main.yml**. В нашем случае — `admin`;
    - `DEPLOY_USER` — имя пользователя для деплоя, создаваемого при выполнении плейбука **ansible\playbooks\create_user.yml**. Само имя задаётся в файле **ansible\group_vars\all**. В нашем случае — `ops`;
    - `STAGE_VM` — IP-адрес машины **stage**;
    - `PROD_VM` — IP-адрес машины **prod**.
3. Склонировать на локальную машину репозитории приложения и его графического интерфейса с содержащимися там файлами **Dockerfile** и **.gitlab-ci.yml**:
    ```bash
    $ git clone https://github.com/rustsh/search_engine_crawler.git
    $ git clone https://github.com/rustsh/search_engine_ui.git
    ```
    *Альтернативный вариант:*
Добавить в свои репозитории с приложением и интерфейсом соответствующие файлы из папки **app-files/** инфраструктурного репозитория, переименовав их в **Dockerfile** и **.gitlab-ci.yml**.
*Важно:*
Если сделать *форк* репозиториев с приложением и интерфейсом, после чего добавить их в Gitlab, то возможны проблемы с публикацией приложения из ветки **master**: сборка может падать при попытке залогиниться на Docker Hub, так как переменная окружения с паролем от учётной записи Docker Hub в этом случае передаёт пустое значение. Это связано с настройками безопасности и особенностями Gitlab.
4. Добавить в каждый из локальных репозиториев приложения ссылку на удалённый репозиторий в Gitlab (в соответствующий проект):
    ```bash
    $ git remote add gitlab http://<ci-IP>/<group-name>/<project-name>.git
    ```
5. В каждом репозитории приложения выполнить команду:
    ```bash
    $ git push gitlab <branch-name>
    ```
    В каждом проекте будет запущен пайплайн по сборке, тестированию и публикации приложения. Если сборка запущена из ветки **master**, то появится дополнительный шаг публикации на сервер **prod**, который необходимо стартовать вручную из графического интерфейса Gitlab. Этот пайплайн будет запускаться при каждом выполнении `push` в удалённый репозиторий **gitlab**.

#### Результат
Приложение опубликовано на машинах **stage** и **prod**, а собранные в результате работы конвейера docker-образы загружены в Docker Hub.

## Удаление проекта
Для того, чтобы удалить всю созданную инфраструктуру, нужно перейти в папку **terraform/** и выполнить команду `terraform destroy`. Дождавшись завершения её работы, перейти в папку **terraform/storage/** и ещё раз выполнить команду `terraform destroy` для удаления облачного хранилища.

#### Результат
Вся созданная в процессе работы облачная инфрастуктура и хранилище для её state-файлов удалены.
